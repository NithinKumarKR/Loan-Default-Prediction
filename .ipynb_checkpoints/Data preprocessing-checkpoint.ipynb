{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc7d92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/04 15:16:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/04 15:16:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "import pylab\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySparkApp\") \\\n",
    "    .getOrCreate()\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import when ,concat,lit , round, mean ,median , col, lit, concat_ws\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34224271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/04 15:16:25 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/Users/nithinkumar/Downloads/df1.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff029b9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51327055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:============================================>            (17 + 5) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2125537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#checking the shape of the dataset\n",
    "print(\"Remaining columns:\", len(df.columns))\n",
    "print(\"Number of rows:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfdbaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['changed_x','changer_x','creator_x','pkey_x'\n",
    "                 ,'pkey_y','changed_y','deleted_y','deleted_x',\n",
    "                 'version_x','version_y','changer_y','created_x',\n",
    "                 'creator_y','trans_status_y','acquirer_country_code_ext',\n",
    "                 'acs_interface','acs_operatorid','acs_reference_number',\n",
    "                 'acs_signed_content','authentication_type','message_version_y',\n",
    "                 'instrument','authentication_value','ds_reference_number',\n",
    "                 'ds_transid','eci','entity_id','error_code_x',\n",
    "     'error_component_x','error_description_x','error_detail_x',\n",
    "                 'error_message_type_x','error_msg_posted_x','kit_no',\n",
    "                 'merchant_fraud_rate','message_version_x','purchase_amount',\n",
    "                 'purchase_exponent','sca_exemption_ind','last_msg_received',\n",
    "                 'sdk_transid_x','secure_corporate_payment','threedsrequestorid',\n",
    "                 'threedsserver_transid_x','threeriind','trans_status_reason',\n",
    "                 'masked_pan','partner_name','product_code','response_code_x','bank_code_x',\n",
    "     'hashed_card','ruleexecutedid','msgreason','rule_result','attempts',\n",
    "                 'authvalue','challenge_no_entry_counter','error_component_x'\n",
    "                 ,'error_code_y','error_description_y','error_detail_y','error_message_type_y',\n",
    "                 'error_msg_posted_y','message_type_y','message_version_y','otp','sdk_transid_y',\n",
    "                 'threedssession_data','otpreferenceid','bank_code_y','response_code_y','opt_method',\n",
    "                 'bank_code_y','response_code_y','masked_pan','sdk_transid_y','threedsserver_transid_y',\n",
    "     'deleted_y','error_code_y','bin','acs_counter_atos','sdk_counter_stoa',\n",
    "                 'threedsrequestor_challenge_ind','acs_counter_atos','interaction_counter',\n",
    "                 'key_index','threedsserver_ref_number','acsurl','auth_type','auth_method',\n",
    "                 'network','acs_challenge_mandated','message_type_y','challenge_received',\n",
    "                 'acs_counter_stoa','dsurl','acs_ui_template','sdk_reference_number','riskscore',\n",
    "                 'ruledetails','frm_tran_id','riskstatus_code',\n",
    "     'riskdescription','acs_ui_type','error_component_y','error_description_y',\n",
    "                 'error_detail_y','error_message_type_y','error_msg_posted_y',\n",
    "                 'switch_reason','flow','cardholder_name','cek','oob_status','oob_description',\n",
    "                 'second_auth','message_type_x']\n",
    "df=df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c224f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acs_transid', 'challenge_completion_ind', 'challenge_window_size', 'msg_reason', 'otp_triggers', 'otp_attempts', 'trans_status_x', 'created_y', 'acct_number', 'acquirerbin', 'acquirer_merchantid', 'card_expiry_date', 'device_channel', 'merchant_country_code', 'merchant_name', 'message_category', 'notificationurl', 'pay_token_ind', 'purchase_currency', 'purchase_date', 'threedscomp_ind', 'threedsrequestor_authentication_ind', 'threedsrequestor_name', 'threedsrequestorurl', 'threedsserverurl', 'trans_type', 'browser_user_agent', 'browserip', 'amount']\n"
     ]
    }
   ],
   "source": [
    "#checking the columns of the dataset\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3de388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:==================================================>     (20 + 2) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column : 'acs_transid' has 6337 null values.\n",
      "Column : 'challenge_completion_ind' has 118371 null values.\n",
      "Column : 'challenge_window_size' has 51518 null values.\n",
      "Column : 'msg_reason' has 121470 null values.\n",
      "Column : 'otp_triggers' has 1777006 null values.\n",
      "Column : 'otp_attempts' has 2078023 null values.\n",
      "Column : 'trans_status_x' has 238242 null values.\n",
      "Column : 'created_y' has 680 null values.\n",
      "Column : 'acct_number' has 6047 null values.\n",
      "Column : 'acquirerbin' has 6325 null values.\n",
      "Column : 'acquirer_merchantid' has 3678 null values.\n",
      "Column : 'card_expiry_date' has 8897 null values.\n",
      "Column : 'device_channel' has 12447 null values.\n",
      "Column : 'merchant_country_code' has 15289 null values.\n",
      "Column : 'merchant_name' has 15277 null values.\n",
      "Column : 'message_category' has 12462 null values.\n",
      "Column : 'notificationurl' has 56909 null values.\n",
      "Column : 'pay_token_ind' has 1503677 null values.\n",
      "Column : 'purchase_currency' has 12507 null values.\n",
      "Column : 'purchase_date' has 12490 null values.\n",
      "Column : 'threedscomp_ind' has 59735 null values.\n",
      "Column : 'threedsrequestor_authentication_ind' has 12728 null values.\n",
      "Column : 'threedsrequestor_name' has 12450 null values.\n",
      "Column : 'threedsrequestorurl' has 12450 null values.\n",
      "Column : 'threedsserverurl' has 12450 null values.\n",
      "Column : 'trans_type' has 15362 null values.\n",
      "Column : 'browser_user_agent' has 59819 null values.\n",
      "Column : 'browserip' has 137233 null values.\n",
      "Column : 'amount' has 12889 null values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#null values count\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "null_counts = []\n",
    "\n",
    "# Iterate over all columns in the DataFrame\n",
    "for col_name in df.columns:\n",
    "    # Count the number of null values for each column\n",
    "    null_count = df.where(col(col_name).isNull()).count()\n",
    "    # Append the result to the list\n",
    "    null_counts.append((col_name, null_count))\n",
    "\n",
    "# Display the null counts for each column\n",
    "for col_name, count in null_counts:\n",
    "    print(f\"Column : '{col_name}' has {count} null values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b712f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/04 15:38:15 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:=============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2124578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 94:===================================================>     (9 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#dulicate values\n",
    "df=df.dropDuplicates()\n",
    "#checking the shape of the dataset\n",
    "print(\"Remaining columns:\", len(df.columns))\n",
    "print(\"Number of rows:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c64189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: 0.27977320672622985 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      7\u001b[0m     null_count \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(col(col_name)\u001b[38;5;241m.\u001b[39misNull())\u001b[38;5;241m.\u001b[39mcount()\n\u001b[0;32m----> 8\u001b[0m     null_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnull_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(col_name, df\u001b[38;5;241m.\u001b[39mselect(col_name)\u001b[38;5;241m.\u001b[39mcount(), null_percentage)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m null_percentage \u001b[38;5;241m>\u001b[39m percentage_threshold:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pyspark/sql/utils.py:159\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pyspark/sql/functions.py:3444\u001b[0m, in \u001b[0;36mround\u001b[0;34m(col, scale)\u001b[0m\n\u001b[1;32m   3416\u001b[0m \u001b[38;5;129m@try_remote_functions\u001b[39m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mround\u001b[39m(col: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m, scale: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m   3418\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3419\u001b[0m \u001b[38;5;124;03m    Round the given value to `scale` decimal places using HALF_UP rounding mode if `scale` >= 0\u001b[39;00m\n\u001b[1;32m   3420\u001b[0m \u001b[38;5;124;03m    or at integral part when `scale` < 0.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[38;5;124;03m    [Row(r=3.0)]\u001b[39;00m\n\u001b[1;32m   3443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43m_to_java_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m, scale)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pyspark/sql/column.py:65\u001b[0m, in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     63\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m _create_column_from_name(col)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument, not a string or column: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor column literals, use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstruct\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_map\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(col, \u001b[38;5;28mtype\u001b[39m(col))\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jcol\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: 0.27977320672622985 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "columns_to_drop = []\n",
    "percentage_threshold = 30\n",
    "\n",
    "for col_name in df.columns:\n",
    "    null_count = df.filter(col(col_name).isNull()).count()\n",
    "    null_percentage = round(null_count * 100 / df.count(), 2)\n",
    "    print(col_name, df.select(col_name).count(), null_percentage)\n",
    "    \n",
    "    if null_percentage > percentage_threshold:\n",
    "        columns_to_drop.append(col_name)\n",
    "\n",
    "# Drop columns with high null percentage\n",
    "df = df.drop(*columns_to_drop)\n",
    "\n",
    "print(\"Columns to drop:\", columns_to_drop)\n",
    "print(\"Remaining columns:\", len(df.columns))\n",
    "print(\"Number of rows:\", df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25999029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- acs_transid: string (nullable = true)\n",
      " |-- challenge_completion_ind: string (nullable = true)\n",
      " |-- challenge_window_size: string (nullable = true)\n",
      " |-- msg_reason: string (nullable = true)\n",
      " |-- otp_triggers: string (nullable = true)\n",
      " |-- otp_attempts: double (nullable = true)\n",
      " |-- trans_status_x: string (nullable = true)\n",
      " |-- created_y: string (nullable = true)\n",
      " |-- acct_number: string (nullable = true)\n",
      " |-- acquirerbin: string (nullable = true)\n",
      " |-- acquirer_merchantid: string (nullable = true)\n",
      " |-- card_expiry_date: double (nullable = true)\n",
      " |-- device_channel: string (nullable = true)\n",
      " |-- merchant_country_code: double (nullable = true)\n",
      " |-- merchant_name: string (nullable = true)\n",
      " |-- message_category: string (nullable = true)\n",
      " |-- notificationurl: string (nullable = true)\n",
      " |-- pay_token_ind: string (nullable = true)\n",
      " |-- purchase_currency: double (nullable = true)\n",
      " |-- purchase_date: double (nullable = true)\n",
      " |-- threedscomp_ind: string (nullable = true)\n",
      " |-- threedsrequestor_authentication_ind: string (nullable = true)\n",
      " |-- threedsrequestor_name: string (nullable = true)\n",
      " |-- threedsrequestorurl: string (nullable = true)\n",
      " |-- threedsserverurl: string (nullable = true)\n",
      " |-- trans_type: string (nullable = true)\n",
      " |-- browser_user_agent: string (nullable = true)\n",
      " |-- browserip: string (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f1fc89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([col(column).alias(column.strip()) for column in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b917b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 174:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+---------------------+--------------------+------------+------------+--------------------+--------------------+--------------------+--------------------+-------------------+----------------+--------------+---------------------+-------------+----------------+---------------+--------------------+-----------------+-------------+---------------+-----------------------------------+---------------------+-------------------+--------------------+----------+------------------+---------+-------------+\n",
      "|         acs_transid|challenge_completion_ind|challenge_window_size|          msg_reason|otp_triggers|otp_attempts|      trans_status_x|           created_y|         acct_number|         acquirerbin|acquirer_merchantid|card_expiry_date|device_channel|merchant_country_code|merchant_name|message_category|notificationurl|       pay_token_ind|purchase_currency|purchase_date|threedscomp_ind|threedsrequestor_authentication_ind|threedsrequestor_name|threedsrequestorurl|    threedsserverurl|trans_type|browser_user_agent|browserip|       amount|\n",
      "+--------------------+------------------------+---------------------+--------------------+------------+------------+--------------------+--------------------+--------------------+--------------------+-------------------+----------------+--------------+---------------------+-------------+----------------+---------------+--------------------+-----------------+-------------+---------------+-----------------------------------+---------------------+-------------------+--------------------+----------+------------------+---------+-------------+\n",
      "|3d604592-bfb3-485...|                       N|                 null|                null|        null|        null|                null|2023-02-02 17:32:...|h9VQ5AxZ0AyYdtkFS...|            442343.0|       980200146994|          2709.0|          null|                 null|         null|            null|           null|                null|             null|         null|           null|                               null|                 null|               null|                null|      null|              null|     null|         null|\n",
      "|38e00b75-6dbf-476...|                       N|                  5.0|               2.2.0|        null|        null|                null|          ACS_SYSTEM|                   1|l6QjayUC0sBKbfISD...|               null|            null|             \u0001|                 null|         null|          HeyTap|          2.2.0|https://checkouts...|           7500.0|        356.0|           null|                                  U|      10062941*904653|         OPPOMobile|c75e76ba-73f8-417...|      null|              null|  10021.0|         null|\n",
      "|374d3a6d-77ff-48c...|                       N|                  2.0|               2.1.0|        null|        null|                null|          ACS_SYSTEM|                   1|eGYPCbUH8Vju3ftQM...|               null|            null|             \u0001|                 null|         null|     P24 DB V US|          2.1.0|https://api.priva...|         253750.0|        980.0|           null|                                  U|    10036784_I0110SW7|        P24 DB V US|e0d99696-5128-4d3...|      null|              null|  10021.0|37.73.156.213|\n",
      "|                null|                   840.0|               PAYPAL|1dafd023-9c90-4c1...|        null|         4.0|3DS_LOA_SER_CACC_...|             10021.0|                null|                null|               null|            null|          null|                 null|         null|            null|           null|                null|             null|         null|           null|                               null|                 null|               null|                null|      null|              null|     null|         null|\n",
      "|                null|                   840.0|               PAYPAL|9fd6ac63-e9bf-40a...|        null|         4.0|3DS_LOA_SER_CACC_...|             10021.0|                null|                null|               null|            null|          null|                 null|         null|            null|           null|                null|             null|         null|           null|                               null|                 null|               null|                null|      null|              null|     null|         null|\n",
      "+--------------------+------------------------+---------------------+--------------------+------------+------------+--------------------+--------------------+--------------------+--------------------+-------------------+----------------+--------------+---------------------+-------------+----------------+---------------+--------------------+-----------------+-------------+---------------+-----------------------------------+---------------------+-------------------+--------------------+----------+------------------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90b424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
